#!/bin/bash -e

wd=$(pwd)
source ./paths
source ./funcs

usage() {
    echo "
    -i,--inputdir : input directory of output from step 1. default is 
                    /n/scratch3/users/a/ak586/microtrawler/1_sequences
    --dbdir : input directory of output from step 0. default is 
                    /n/scratch3/users/a/ak586/microtrawler/0_databases
    -o,--outputdir: base output directory for rgi. default is 
                    /n/scratch3/users/a/ak586/microtrawler/2_analyze-seqs
    -c,--commands: number of commands to submit per job. default is 50
    "
}

build_files() {
    rm -f $BASEOUTPUTDIR/output_dirs 2> /dev/null
    fd "*.fa" -a $INPUTDIR --glob | sort > $BASEOUTPUTDIR/input_fastas
    for i in $(fd "*.fa" --base-directory $INPUTDIR --glob | sort)
    do 
        x=$(dirname $(dirname $i))
        y=$(basename $i .fa)
        echo "$BASEOUTPUTDIR/$x/$y" >> $BASEOUTPUTDIR/output_dirs
    done
}

build_files_strain() {
    rm -f "$BASEOUTPUTDIR/output_$STRAIN-dirs" 2> /dev/null
    STRAIN=$1
    awk -F'\t' -v s="$STRAIN" '{if(match($3, s)){print $0}}' $DBDIR/nctc_db.csv \
        | cut -f2 | tr -d ' ' | sed 's:^:/:g' | sed 's:$:/:g'\
        > $BASEOUTPUTDIR/"acc_$STRAIN"
    fd "*.fa" -a $INPUTDIR --glob | grep -f $BASEOUTPUTDIR/"acc_$STRAIN" \
        | sort > "$BASEOUTPUTDIR/input_$STRAIN-fastas"

    for i in $(fd "*.fa" --base-directory $INPUTDIR --glob \
        | grep -f $BASEOUTPUTDIR/"acc_$STRAIN" | sort)
    do
        x=$(dirname $(dirname $i))
        y=$(basename $i .fa)
        echo "$BASEOUTPUTDIR/$x/$y" >> "$BASEOUTPUTDIR/output_$STRAIN-dirs"
    done
}


create_rgi_jobs() {
    mapfile -t fasta_input_list < $BASEOUTPUTDIR/input_fastas
    mapfile -t output_dir_list < $BASEOUTPUTDIR/output_dirs
    jobctr=0
    rgictr=0
    for i in "${!fasta_input_list[@]}"; do
        outdir="${output_dir_list[i]}"
        mkdir -p "$outdir"
        fasta="${fasta_input_list[i]}"
        fasta_fname="$(basename $fasta .fa)"
        output_basename="$outdir"/"$fasta_fname"_abr-search
        if [ -s "$output_basename".rgi_out.json ]; then
            log "RGI" "$fasta already analyzed! Skipping."
        else
            log "RGI" "Adding $fasta"
            if [ $rgictr -eq 0 ] || [ $rgictr -eq $1 ]; then
                rgictr=1
                job="$BASEOUTPUTDIR/jobs/FINDRESISTANCE_$jobctr-microtrawler.job"
                cp $jobt_2 $job
                sed -i "2i #SBATCH -o $BASEOUTPUTDIR/jobs/outputs/JOBOUTPUT_$jobctr-find-resistance" $job
                echo "
                if [ ! -s $BASEOUTPUTDIR/card/card.json ]; then
                    wget --output-document "$BASEOUTPUTDIR/carddb" https://card.mcmaster.ca/latest/data
                    mkdir -p $BASEOUTPUTDIR/data/rgi
                    tar -xvf $BASEOUTPUTDIR/carddb --directory $BASEOUTPUTDIR/data/rgi
                fi" >> $job
                echo "rgi load --card_json $BASEOUTPUTDIR/data/rgi/card.json" >> $job
                ((jobctr++)) || true
            fi
            echo "rgi main -i "$fasta" -o "$output_basename".rgi_out --input_type contig --exclude_nudge --clean --split_prodigal_jobs -n 12" >> $job
            echo ""$fasta" > $outdir/fasta_analyzed" >> $job
            echo "echo "Finished analyzing $fasta"" >> $job
            ((rgictr++)) || true
        fi
    done
}

create_integron_jobs() {
    mapfile -t fasta_input_list < $BASEOUTPUTDIR/input_fastas
    mapfile -t output_dir_list < $BASEOUTPUTDIR/output_dirs
    jobctr=0
    integctr=0
    for i in "${!fasta_input_list[@]}"; do
        outdir="${output_dir_list[i]}/integrons"
        mkdir -p "$outdir"
        fasta="${fasta_input_list[i]}"
        fasta_fname="$(basename $fasta .fa)"
        if [ -s "$outdir"/Results_Integron_Finder_$fasta_fname/integron_finder.out ]; then
            log "Integron" "$fasta already analyzed! Skipping."
        else
            log "Integron" "Adding $fasta"
            if [ $integctr -eq 0 ] || [ $integctr -eq $1 ]; then
                integctr=1
                job="$BASEOUTPUTDIR/jobs/FINDINTEGRONS_$jobctr-microtrawler.job"
                cp $jobt_2 $job
                sed -i "2i #SBATCH -o $BASEOUTPUTDIR/jobs/outputs/JOBOUTPUT_$jobctr-find-integrons" $job
                ((jobctr++)) || true
            fi
            echo "integron_finder --keep-tmp --outdir $outdir $fasta" >> $job
            echo "echo "Finished analyzing $fasta"" >> $job
            ((integctr++)) || true
        fi
    done
}

create_plasmidfinder_jobs() {
    mapfile -t fasta_input_list < $BASEOUTPUTDIR/input_fastas
    mapfile -t output_dir_list < $BASEOUTPUTDIR/output_dirs
    jobctr=0
    plasmidctr=0
    for i in "${!fasta_input_list[@]}"; do
        outdir="${output_dir_list[i]}/plasmid"
        mkdir -p "$outdir"
        fasta="${fasta_input_list[i]}"
        fasta_fname="$(basename $fasta .fa)"
        if [ -s "$outdir"/data.json ]; then
            log "PlasmidFinder" "$fasta already analyzed! Skipping."
        else
            log "PlasmidFinder" "Adding $fasta"
            if [ $plasmidctr -eq 0 ] || [ $plasmidctr -eq $1 ]; then
                plasmidctr=1
                job="$BASEOUTPUTDIR/jobs/FINDPLAMIDS_$jobctr-microtrawler.job"
                cp $jobt_2 $job
                sed -i "2i #SBATCH -o $BASEOUTPUTDIR/jobs/outputs/JOBOUTPUT_$jobctr-find-plasmids" $job
                ((jobctr++)) || true
            fi
            echo "plasmidfinder.py -i $fasta -o $outdir" >> $job
            echo "echo "Finished analyzing $fasta"" >> $job
            ((plasmidctr++)) || true
        fi
    done
}

create_crispr_jobs() {
    mapfile -t fasta_input_list < $BASEOUTPUTDIR/input_fastas
    mapfile -t output_dir_list < $BASEOUTPUTDIR/output_dirs
    jobctr=0
    crisprctr=0
    for i in "${!fasta_input_list[@]}"; do
        outdir="${output_dir_list[i]}/cctyper"
        fasta="${fasta_input_list[i]}"
        fasta_fname="$(basename $fasta .fa)"
        if [ -s "$outdir/CRISPR_Cas.tab" ]; then
            log "CRISPR" "$fasta already analyzed! Skipping."
        else
            log "CRISPR" "Adding $fasta"
            if [ $crisprctr -eq 0 ] || [ $crisprctr -eq $1 ]; then
                crisprctr=1
                job="$BASEOUTPUTDIR/jobs/FINDCRISPR_$jobctr-microtrawler.job"
                cp $jobt_2 $job
                sed -i "2i #SBATCH -o $BASEOUTPUTDIR/jobs/outputs/JOBOUTPUT_$jobctr-find-crispr" $job
                ((jobctr++)) || true
            fi
            echo "cctyper $fasta $outdir" >> $job
            echo "echo "Finished analyzing $fasta"" >> $job
            ((crisprctr++)) || true
        fi
    done
}

create_mlplasmids_jobs() {
    STRAIN=$1
    build_files_strain "$STRAIN"
    mapfile -t fasta_input_list < "$BASEOUTPUTDIR/input_$STRAIN-fastas"
    mapfile -t output_dir_list < "$BASEOUTPUTDIR/output_$STRAIN-dirs"
    jobctr=0
    plasmidctr=0
    for i in "${!fasta_input_list[@]}"; do
        outdir="${output_dir_list[i]}/plasmid"
        mkdir -p "$outdir"
        fasta="${fasta_input_list[i]}"
        fasta_fname="$(basename $fasta .fa)"
        if [ -s "$outdir"/mlplasmids_out.tab ]; then
            log "mlplasmid" "$fasta already analyzed! Skipping."
        else
            log "mlplasmid" "Adding $fasta"
            job="$BASEOUTPUTDIR/jobs/FINDMLPLAMIDS_$STRAIN-microtrawler.job"
            [ ! -s "$job" ] && (cp $jobt_2 "$job"; sed -i "2i #SBATCH -o "$BASEOUTPUTDIR/jobs/outputs/JOBOUTPUT_\'$STRAIN\'-find-plasmids"" "$job")
            echo "module load gcc; module load R/3.6.1.lua" >> "$job"
            echo "Rscript $tooldir/mlplasmids/scripts/run_mlplasmids.R $fasta $outdir/mlplasmids_out.tab 0.7 '$STRAIN'" >> "$job"
            echo "echo "Finished analyzing $fasta"" >> "$job"
        fi
    done
}

submit_jobs() {
    joblist=""
    if [ -z $DEPENDENCY ]; then
        for j in $(fd -a "FIND*-microtrawler.job" --glob $BASEOUTPUTDIR/jobs); do
            jobid=$(sbatch "$j" | cut -d' ' -f4)
            joblist+="$jobid:"
        done
    else
        for j in $(fd -a "FIND*-microtrawler.job" --glob $BASEOUTPUTDIR/jobs); do
            jobid=$(sbatch --dependency=afterok:"$DEPENDENCY" "$j" | cut -d' ' -f4)
            joblist+="$jobid:"
        done
    fi
    echo $joblist
}

main() {
    INPUTDIR="/n/scratch3/users/a/ak586/microtrawler/1_sequences"
    BASEOUTPUTDIR="/n/scratch3/users/a/ak586/microtrawler/2_analyze-seqs"
    DBDIR="/n/scratch3/users/a/ak586/microtrawler/0_databases"
    COMMANDS=50
    for i in "$@"; do
    case $i in
        -i|--inputdir)
        INPUTDIR="$2"
        shift
        shift
        ;;
        -o|--outputdir)
        BASEOUTPUTDIR="$2"
        shift
        shift
        ;;
        -c|--commands)
        COMMANDS="$2"
        shift
        shift
        ;;
        -d|--dependency)
        DEPENDENCY="$2"
        shift
        shift
        ;;
        --dbdir)
        DBDIR="$2"
        shift
        shift
        ;;
        -h|--help)
        usage
        exit
        ;;
        *)
        ;;
    esac
    done

    rm -r "$BASEOUTPUTDIR/jobs" 2> /dev/null
    mkdir -p "$BASEOUTPUTDIR/jobs/outputs"

    log "Building files..."
    build_files
    log "Built files"
    create_rgi_jobs $COMMANDS
    #create_integron_jobs $COMMANDS
    #create_crispr_jobs $COMMANDS
    #create_plasmid_jobs $COMMANDS
    #for i in "Klebsiella pneumoniae" "Escherichia coli" "Enterococcus faecium" "Enterococcus faecalis" "Acinetobacter baumannii"
    #do
        #create_mlplasmids_jobs "$i" $COMMANDS
    #done
    #submit_jobs
}
main "$@"
